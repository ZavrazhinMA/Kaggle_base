{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de73ca87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:06:37.893511Z",
     "iopub.status.busy": "2021-11-20T09:06:37.892387Z",
     "iopub.status.idle": "2021-11-20T09:06:38.822222Z",
     "shell.execute_reply": "2021-11-20T09:06:38.821428Z",
     "shell.execute_reply.started": "2021-11-20T09:05:47.562535Z"
    },
    "papermill": {
     "duration": 0.970535,
     "end_time": "2021-11-20T09:06:38.822417",
     "exception": false,
     "start_time": "2021-11-20T09:06:37.851882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "339f2215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:06:38.888929Z",
     "iopub.status.busy": "2021-11-20T09:06:38.888129Z",
     "iopub.status.idle": "2021-11-20T09:06:48.139497Z",
     "shell.execute_reply": "2021-11-20T09:06:48.138934Z"
    },
    "papermill": {
     "duration": 9.287149,
     "end_time": "2021-11-20T09:06:48.139783",
     "exception": false,
     "start_time": "2021-11-20T09:06:38.852634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm_notebook\n",
    "import torchvision.transforms as T\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import timm\n",
    "import tez\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c0f7b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:06:48.250320Z",
     "iopub.status.busy": "2021-11-20T09:06:48.249446Z",
     "iopub.status.idle": "2021-11-20T09:06:48.260105Z",
     "shell.execute_reply": "2021-11-20T09:06:48.260975Z"
    },
    "papermill": {
     "duration": 0.093155,
     "end_time": "2021-11-20T09:06:48.261244",
     "exception": false,
     "start_time": "2021-11-20T09:06:48.168089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24120a39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:06:48.327494Z",
     "iopub.status.busy": "2021-11-20T09:06:48.326348Z",
     "iopub.status.idle": "2021-11-20T09:06:48.328627Z",
     "shell.execute_reply": "2021-11-20T09:06:48.329737Z"
    },
    "papermill": {
     "duration": 0.038099,
     "end_time": "2021-11-20T09:06:48.329914",
     "exception": false,
     "start_time": "2021-11-20T09:06:48.291815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = '/kaggle/input/petfinder-pawpularity-score/'\n",
    "IMG_SIZE = 384\n",
    "BATCH_SIZE = 12\n",
    "model_name = 'swin_large_patch4_window12_384'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f257d864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:06:48.396715Z",
     "iopub.status.busy": "2021-11-20T09:06:48.395867Z",
     "iopub.status.idle": "2021-11-20T09:06:48.469792Z",
     "shell.execute_reply": "2021-11-20T09:06:48.470472Z"
    },
    "papermill": {
     "duration": 0.110577,
     "end_time": "2021-11-20T09:06:48.470695",
     "exception": false,
     "start_time": "2021-11-20T09:06:48.360118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  kfold  \n",
       "0          0      1        0      0          0     0     0           63      1  \n",
       "1          0      0        0      0          0     0     0           42      5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../input/train-data-10/10FOLDSTRAIN.csv')\n",
    "df_test = pd.read_csv(PATH + 'test.csv')\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d20dd38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:06:48.844670Z",
     "iopub.status.busy": "2021-11-20T09:06:48.843989Z",
     "iopub.status.idle": "2021-11-20T09:06:48.848680Z",
     "shell.execute_reply": "2021-11-20T09:06:48.848119Z"
    },
    "papermill": {
     "duration": 0.040583,
     "end_time": "2021-11-20T09:06:48.848868",
     "exception": false,
     "start_time": "2021-11-20T09:06:48.808285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# *************************************************\n",
    "FOLD = 0\n",
    "# *************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd10482c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:06:48.918230Z",
     "iopub.status.busy": "2021-11-20T09:06:48.917130Z",
     "iopub.status.idle": "2021-11-20T09:06:48.924335Z",
     "shell.execute_reply": "2021-11-20T09:06:48.925048Z"
    },
    "papermill": {
     "duration": 0.045553,
     "end_time": "2021-11-20T09:06:48.925234",
     "exception": false,
     "start_time": "2021-11-20T09:06:48.879681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8870 988\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.loc[df_train['kfold'] != FOLD]\n",
    "X_valid = df_train.loc[df_train['kfold'] == FOLD]\n",
    "print(len(X_train), len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b8b8a00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:06:48.997145Z",
     "iopub.status.busy": "2021-11-20T09:06:48.995973Z",
     "iopub.status.idle": "2021-11-20T09:06:48.998447Z",
     "shell.execute_reply": "2021-11-20T09:06:48.999086Z"
    },
    "papermill": {
     "duration": 0.04239,
     "end_time": "2021-11-20T09:06:48.999292",
     "exception": false,
     "start_time": "2021-11-20T09:06:48.956902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "augm_train = T.Compose([T.ToPILImage(),\n",
    "#                         T.RandomHorizontalFlip(p=0.2),\n",
    "                        T.Resize([IMG_SIZE, IMG_SIZE]),\n",
    "                        T.ToTensor(),\n",
    "                        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                       ])\n",
    "\n",
    "augm_test = T.Compose([T.ToPILImage(),\n",
    "                       T.Resize([IMG_SIZE, IMG_SIZE]),\n",
    "                       T.ToTensor(),\n",
    "                       T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "131afeb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:06:49.084381Z",
     "iopub.status.busy": "2021-11-20T09:06:49.083569Z",
     "iopub.status.idle": "2021-11-20T09:06:49.088264Z",
     "shell.execute_reply": "2021-11-20T09:06:49.088878Z"
    },
    "papermill": {
     "duration": 0.053251,
     "end_time": "2021-11-20T09:06:49.089061",
     "exception": false,
     "start_time": "2021-11-20T09:06:49.035810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PawDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, image_path='train/', augm=False):\n",
    "        self.df = df.copy()\n",
    "        self.augm = augm\n",
    "        self.img_path = PATH + image_path\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.img_path + str(self.df.iloc[idx, 0]) + '.jpg')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = self.augm(image)\n",
    "\n",
    "        target = self.df.iloc[idx, -1:]\n",
    "        features = torch.FloatTensor(self.df.iloc[idx, 1:-1].values.astype('float32'))\n",
    "        target = torch.FloatTensor(target.values.astype('float32'))\n",
    "    \n",
    "\n",
    "        return image, features, target/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce84016f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:06:49.173223Z",
     "iopub.status.busy": "2021-11-20T09:06:49.172342Z",
     "iopub.status.idle": "2021-11-20T09:06:49.180297Z",
     "shell.execute_reply": "2021-11-20T09:06:49.179407Z"
    },
    "papermill": {
     "duration": 0.054395,
     "end_time": "2021-11-20T09:06:49.180448",
     "exception": false,
     "start_time": "2021-11-20T09:06:49.126053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = PawDataset(X_train.drop(columns='kfold'), augm=augm_train)\n",
    "valid_data = PawDataset(X_valid.drop(columns='kfold'), augm=augm_test)\n",
    "test_data = PawDataset(df_test, image_path='test/', augm=augm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21d2936a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:06:49.260864Z",
     "iopub.status.busy": "2021-11-20T09:06:49.259724Z",
     "iopub.status.idle": "2021-11-20T09:06:49.262126Z",
     "shell.execute_reply": "2021-11-20T09:06:49.262675Z"
    },
    "papermill": {
     "duration": 0.046018,
     "end_time": "2021-11-20T09:06:49.262856",
     "exception": false,
     "start_time": "2021-11-20T09:06:49.216838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=8)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=BATCH_SIZE*4, shuffle=False, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE*4, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74d9dd4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:06:49.335670Z",
     "iopub.status.busy": "2021-11-20T09:06:49.334953Z",
     "iopub.status.idle": "2021-11-20T09:07:07.849836Z",
     "shell.execute_reply": "2021-11-20T09:07:07.849195Z"
    },
    "papermill": {
     "duration": 18.555025,
     "end_time": "2021-11-20T09:07:07.850001",
     "exception": false,
     "start_time": "2021-11-20T09:06:49.294976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22kto1k.pth\" to /root/.cache/torch/hub/checkpoints/swin_large_patch4_window12_384_22kto1k.pth\n"
     ]
    }
   ],
   "source": [
    "model_ = timm.create_model(model_name, pretrained=True, in_chans=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f0fc6a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:07:07.929030Z",
     "iopub.status.busy": "2021-11-20T09:07:07.928037Z",
     "iopub.status.idle": "2021-11-20T09:07:07.934406Z",
     "shell.execute_reply": "2021-11-20T09:07:07.933843Z"
    },
    "papermill": {
     "duration": 0.049984,
     "end_time": "2021-11-20T09:07:07.934554",
     "exception": false,
     "start_time": "2021-11-20T09:07:07.884570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for param in model_.parameters():\n",
    "    param.requires_grad = False\n",
    "model_.head = nn.Linear(1536, 128)\n",
    "model_.head.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41ec1960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:07:08.011384Z",
     "iopub.status.busy": "2021-11-20T09:07:08.010257Z",
     "iopub.status.idle": "2021-11-20T09:07:08.012654Z",
     "shell.execute_reply": "2021-11-20T09:07:08.013492Z"
    },
    "papermill": {
     "duration": 0.045963,
     "end_time": "2021-11-20T09:07:08.013754",
     "exception": false,
     "start_time": "2021-11-20T09:07:07.967791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyNetFeat(tez.Model):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.model = base_model\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(147, 72)\n",
    "        self.dense2 = nn.Linear(72, 1)\n",
    "\n",
    "\n",
    "    def forward(self, image, features, targets=None):\n",
    "        x = self.model(image)\n",
    "        x2 = torch.cat([x, features], dim=1)\n",
    "        x = self.dense1(x2)\n",
    "#         x = self.dropout2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        return x, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6dadbb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:07:08.088499Z",
     "iopub.status.busy": "2021-11-20T09:07:08.087382Z",
     "iopub.status.idle": "2021-11-20T09:07:08.090829Z",
     "shell.execute_reply": "2021-11-20T09:07:08.090169Z"
    },
    "papermill": {
     "duration": 0.041987,
     "end_time": "2021-11-20T09:07:08.090975",
     "exception": false,
     "start_time": "2021-11-20T09:07:08.048988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# net = torch.load('../input/my-img-models/img_models/only_img_model_0_1785.pht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec21c5e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:07:08.165257Z",
     "iopub.status.busy": "2021-11-20T09:07:08.164473Z",
     "iopub.status.idle": "2021-11-20T09:07:13.723364Z",
     "shell.execute_reply": "2021-11-20T09:07:13.723956Z"
    },
    "papermill": {
     "duration": 5.599332,
     "end_time": "2021-11-20T09:07:13.724158",
     "exception": false,
     "start_time": "2021-11-20T09:07:08.124826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNetFeat(\n",
       "  (model): SwinTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (0): BasicLayer(\n",
       "        dim=192, input_resolution=(96, 96), depth=2\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          input_resolution=(96, 96), dim=192\n",
       "          (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicLayer(\n",
       "        dim=384, input_resolution=(48, 48), depth=2\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          input_resolution=(48, 48), dim=384\n",
       "          (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): BasicLayer(\n",
       "        dim=768, input_resolution=(24, 24), depth=18\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (12): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (13): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (14): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (15): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (16): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (17): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          input_resolution=(24, 24), dim=768\n",
       "          (reduction): Linear(in_features=3072, out_features=1536, bias=False)\n",
       "          (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (3): BasicLayer(\n",
       "        dim=1536, input_resolution=(12, 12), depth=2\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath()\n",
       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "    (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "    (head): Linear(in_features=1536, out_features=128, bias=True)\n",
       "  )\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (dense1): Linear(in_features=147, out_features=72, bias=True)\n",
       "  (dense2): Linear(in_features=72, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = MyNetFeat(base_model=model_)\n",
    "net2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "266ea881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:07:13.801721Z",
     "iopub.status.busy": "2021-11-20T09:07:13.800606Z",
     "iopub.status.idle": "2021-11-20T09:07:13.803246Z",
     "shell.execute_reply": "2021-11-20T09:07:13.803955Z"
    },
    "papermill": {
     "duration": 0.045127,
     "end_time": "2021-11-20T09:07:13.804150",
     "exception": false,
     "start_time": "2021-11-20T09:07:13.759023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def rmse_func(y_pred, y_true):\n",
    "    y_ = 100 * y_true\n",
    "    pred_ =  sigmoid(y_pred)*100\n",
    "    return np.sqrt(mse(y_, pred_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df0c4dd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:07:13.881320Z",
     "iopub.status.busy": "2021-11-20T09:07:13.880209Z",
     "iopub.status.idle": "2021-11-20T09:07:13.882489Z",
     "shell.execute_reply": "2021-11-20T09:07:13.883110Z"
    },
    "papermill": {
     "duration": 0.044766,
     "end_time": "2021-11-20T09:07:13.883278",
     "exception": false,
     "start_time": "2021-11-20T09:07:13.838512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model, mod_path, prefix, metric, verbose=True):\n",
    "    path_1 = mod_path + prefix   \n",
    "    for f in glob.glob(path_1+\"*\"):\n",
    "        os.remove(f)\n",
    "    full_path = path_1 + str(round(metric*100)) +'.pht'\n",
    "    torch.save(model, full_path)\n",
    "    if verbose:\n",
    "        print(f'Model saved with metric: {round(metric,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f154726e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:07:13.962694Z",
     "iopub.status.busy": "2021-11-20T09:07:13.961865Z",
     "iopub.status.idle": "2021-11-20T09:07:13.965890Z",
     "shell.execute_reply": "2021-11-20T09:07:13.965271Z"
    },
    "papermill": {
     "duration": 0.048158,
     "end_time": "2021-11-20T09:07:13.966052",
     "exception": false,
     "start_time": "2021-11-20T09:07:13.917894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_eval(model, opt, loss_func, dataset_loader):\n",
    "\n",
    "    num_batches = len(dataset_loader)\n",
    "    test_loss = 0\n",
    "    rmse = 0\n",
    "    full_y = np.array([])\n",
    "    full_pred = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for X, features, y in dataset_loader:\n",
    "            pred, _ = model(X.to(device), features.to(device))\n",
    "            test_loss += criterion(pred, y.to(device)).item()\n",
    "            full_y = np.append(full_y, y.cpu().numpy())\n",
    "            full_pred = np.append(full_pred, pred.cpu().numpy())\n",
    "\n",
    "\n",
    "        test_loss = round(test_loss / num_batches, 4)\n",
    "        rmse = rmse_func(full_pred, full_y)\n",
    "        \n",
    "\n",
    "    return test_loss, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1377f12e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:07:14.049721Z",
     "iopub.status.busy": "2021-11-20T09:07:14.048574Z",
     "iopub.status.idle": "2021-11-20T09:07:14.051076Z",
     "shell.execute_reply": "2021-11-20T09:07:14.051631Z"
    },
    "papermill": {
     "duration": 0.050714,
     "end_time": "2021-11-20T09:07:14.051832",
     "exception": false,
     "start_time": "2021-11-20T09:07:14.001118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(epoch, train_start_time, model, opt, loss_func, train_loader, step, best_metric):\n",
    "\n",
    "    time_start = time.time()\n",
    "    running_loss = 0\n",
    "    num_batches_train = len(train_loader)\n",
    "\n",
    "    for num, data in enumerate(train_loader):\n",
    "        images, features, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "\n",
    "        opt.zero_grad()  # обнуляем градиент\n",
    "        outputs, _ = model(images, features)  # получаем предсказания\n",
    "        loss = loss_func(outputs, labels)  # считаем потери\n",
    "        loss.backward()  # ОРО\n",
    "        opt.step()  # обновление весов\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (num+1) % step == 0:\n",
    "            test_loss, rmse = model_eval(model, opt, loss_func, valid_loader)\n",
    "#             save_model(net, mod_path='./' , prefix='only_img_model', metric=rmse)\n",
    "            print(\n",
    "            f'IT № {num+1}/{num_batches_train}, tr_loss= {round(running_loss/(num+1), 4)}, eval_loss= {test_loss},',\n",
    "            f'rmse = {round(rmse,3)}'\n",
    "        )\n",
    "            if rmse < best_metric:\n",
    "                best_metric = rmse\n",
    "                save_model(model, mod_path='./', prefix=f'full_mod_{FOLD}_', metric=best_metric)\n",
    "\n",
    "    test_loss, rmse = model_eval(model, opt, loss_func, valid_loader)\n",
    "    train_loss = round(running_loss / num_batches_train, 4)\n",
    "\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        time_taken = round(time.time() - time_start, 1)\n",
    "        from_start = round(time.time() - train_start_time, 1)\n",
    "        print(\n",
    "            f'Epoch № {epoch+1}, tr_loss= {train_loss}, eval_loss= {test_loss},',\n",
    "            f'rmse = {rmse}',\n",
    "            f'\\ntime_per_epoch = {time_taken} sec, total ---> {from_start} sec'\n",
    "        )\n",
    "    return rmse, best_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "180968c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:07:14.130842Z",
     "iopub.status.busy": "2021-11-20T09:07:14.129971Z",
     "iopub.status.idle": "2021-11-20T09:07:14.132981Z",
     "shell.execute_reply": "2021-11-20T09:07:14.133524Z"
    },
    "papermill": {
     "duration": 0.047392,
     "end_time": "2021-11-20T09:07:14.133695",
     "exception": false,
     "start_time": "2021-11-20T09:07:14.086303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EPOCHES = 8\n",
    "criterion  = nn.BCEWithLogitsLoss()\n",
    "opt = optim.Adam(net2.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(opt, milestones=[1,2,3,4,5], gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69a8eb56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T09:07:14.213350Z",
     "iopub.status.busy": "2021-11-20T09:07:14.212233Z",
     "iopub.status.idle": "2021-11-20T13:59:43.132395Z",
     "shell.execute_reply": "2021-11-20T13:59:43.128678Z"
    },
    "papermill": {
     "duration": 17548.964307,
     "end_time": "2021-11-20T13:59:43.132630",
     "exception": false,
     "start_time": "2021-11-20T09:07:14.168323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa73d9a9e5b44ae7b37cb9bd6b56cc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************** EPOCH № 1 ****************************************\n",
      "IT № 300/739, tr_loss= 0.6521, eval_loss= 0.6476, rmse = 18.65\n",
      "Model saved with metric: 18.65\n",
      "IT № 600/739, tr_loss= 0.6492, eval_loss= 0.6428, rmse = 17.981\n",
      "Model saved with metric: 17.98\n",
      "Epoch № 1, tr_loss= 0.6484, eval_loss= 0.6459, rmse = 18.35956968602556 \n",
      "time_per_epoch = 589.7 sec, total ---> 589.8 sec\n",
      "**************************************** EPOCH № 2 ****************************************\n",
      "IT № 20/739, tr_loss= 0.6421, eval_loss= 0.6441, rmse = 18.203\n",
      "IT № 40/739, tr_loss= 0.6407, eval_loss= 0.6436, rmse = 18.123\n",
      "IT № 60/739, tr_loss= 0.6397, eval_loss= 0.6466, rmse = 18.492\n",
      "IT № 80/739, tr_loss= 0.6363, eval_loss= 0.6467, rmse = 18.428\n",
      "IT № 100/739, tr_loss= 0.6366, eval_loss= 0.6447, rmse = 18.255\n",
      "IT № 120/739, tr_loss= 0.6352, eval_loss= 0.6449, rmse = 18.3\n",
      "IT № 140/739, tr_loss= 0.6362, eval_loss= 0.6442, rmse = 18.173\n",
      "IT № 160/739, tr_loss= 0.6358, eval_loss= 0.6441, rmse = 18.184\n",
      "IT № 180/739, tr_loss= 0.6347, eval_loss= 0.6518, rmse = 19.031\n",
      "IT № 200/739, tr_loss= 0.635, eval_loss= 0.6466, rmse = 18.492\n",
      "IT № 220/739, tr_loss= 0.6353, eval_loss= 0.6461, rmse = 18.432\n",
      "IT № 240/739, tr_loss= 0.6351, eval_loss= 0.6434, rmse = 18.084\n",
      "IT № 260/739, tr_loss= 0.6352, eval_loss= 0.6436, rmse = 18.09\n",
      "IT № 280/739, tr_loss= 0.6346, eval_loss= 0.6465, rmse = 18.453\n",
      "IT № 300/739, tr_loss= 0.635, eval_loss= 0.6448, rmse = 18.218\n",
      "IT № 320/739, tr_loss= 0.6357, eval_loss= 0.6436, rmse = 18.13\n",
      "IT № 340/739, tr_loss= 0.6361, eval_loss= 0.6435, rmse = 18.125\n",
      "IT № 360/739, tr_loss= 0.6364, eval_loss= 0.6443, rmse = 18.2\n",
      "IT № 380/739, tr_loss= 0.6365, eval_loss= 0.6445, rmse = 18.265\n",
      "IT № 400/739, tr_loss= 0.6363, eval_loss= 0.6459, rmse = 18.439\n",
      "IT № 420/739, tr_loss= 0.6363, eval_loss= 0.6486, rmse = 18.679\n",
      "IT № 440/739, tr_loss= 0.6365, eval_loss= 0.6458, rmse = 18.4\n",
      "IT № 460/739, tr_loss= 0.637, eval_loss= 0.6437, rmse = 18.155\n",
      "IT № 480/739, tr_loss= 0.6368, eval_loss= 0.6445, rmse = 18.214\n",
      "IT № 500/739, tr_loss= 0.6373, eval_loss= 0.6463, rmse = 18.463\n",
      "IT № 520/739, tr_loss= 0.6375, eval_loss= 0.6443, rmse = 18.201\n",
      "IT № 540/739, tr_loss= 0.6377, eval_loss= 0.6469, rmse = 18.506\n",
      "IT № 560/739, tr_loss= 0.6379, eval_loss= 0.6459, rmse = 18.366\n",
      "IT № 580/739, tr_loss= 0.6377, eval_loss= 0.6441, rmse = 18.169\n",
      "IT № 600/739, tr_loss= 0.6381, eval_loss= 0.6437, rmse = 18.167\n",
      "IT № 620/739, tr_loss= 0.6387, eval_loss= 0.6438, rmse = 18.178\n",
      "IT № 640/739, tr_loss= 0.6388, eval_loss= 0.644, rmse = 18.186\n",
      "IT № 660/739, tr_loss= 0.6388, eval_loss= 0.6462, rmse = 18.456\n",
      "IT № 680/739, tr_loss= 0.6386, eval_loss= 0.6464, rmse = 18.41\n",
      "IT № 700/739, tr_loss= 0.6385, eval_loss= 0.646, rmse = 18.379\n",
      "IT № 720/739, tr_loss= 0.6385, eval_loss= 0.6445, rmse = 18.228\n",
      "Epoch № 2, tr_loss= 0.6384, eval_loss= 0.6447, rmse = 18.23534683139946 \n",
      "time_per_epoch = 2431.0 sec, total ---> 3020.8 sec\n",
      "**************************************** EPOCH № 3 ****************************************\n",
      "IT № 20/739, tr_loss= 0.6424, eval_loss= 0.6449, rmse = 18.246\n",
      "IT № 40/739, tr_loss= 0.6404, eval_loss= 0.6447, rmse = 18.283\n",
      "IT № 60/739, tr_loss= 0.6382, eval_loss= 0.6449, rmse = 18.276\n",
      "IT № 80/739, tr_loss= 0.6371, eval_loss= 0.6448, rmse = 18.254\n",
      "IT № 100/739, tr_loss= 0.6367, eval_loss= 0.6472, rmse = 18.543\n",
      "IT № 120/739, tr_loss= 0.6365, eval_loss= 0.6456, rmse = 18.346\n",
      "IT № 140/739, tr_loss= 0.6372, eval_loss= 0.6455, rmse = 18.323\n",
      "IT № 160/739, tr_loss= 0.6359, eval_loss= 0.6442, rmse = 18.174\n",
      "IT № 180/739, tr_loss= 0.637, eval_loss= 0.6426, rmse = 18.004\n",
      "IT № 200/739, tr_loss= 0.6368, eval_loss= 0.6432, rmse = 18.074\n",
      "IT № 220/739, tr_loss= 0.6362, eval_loss= 0.643, rmse = 18.051\n",
      "IT № 240/739, tr_loss= 0.6361, eval_loss= 0.6431, rmse = 18.07\n",
      "IT № 260/739, tr_loss= 0.6356, eval_loss= 0.6442, rmse = 18.173\n",
      "IT № 280/739, tr_loss= 0.6356, eval_loss= 0.6433, rmse = 18.1\n",
      "IT № 300/739, tr_loss= 0.6355, eval_loss= 0.6438, rmse = 18.132\n",
      "IT № 320/739, tr_loss= 0.6352, eval_loss= 0.6435, rmse = 18.108\n",
      "IT № 340/739, tr_loss= 0.6355, eval_loss= 0.6432, rmse = 18.05\n",
      "IT № 360/739, tr_loss= 0.6354, eval_loss= 0.6435, rmse = 18.101\n",
      "IT № 380/739, tr_loss= 0.6345, eval_loss= 0.6464, rmse = 18.381\n",
      "IT № 400/739, tr_loss= 0.6341, eval_loss= 0.6443, rmse = 18.163\n",
      "IT № 420/739, tr_loss= 0.6346, eval_loss= 0.6446, rmse = 18.184\n",
      "IT № 440/739, tr_loss= 0.6349, eval_loss= 0.644, rmse = 18.197\n",
      "IT № 460/739, tr_loss= 0.6348, eval_loss= 0.6422, rmse = 17.949\n",
      "Model saved with metric: 17.95\n",
      "IT № 480/739, tr_loss= 0.6345, eval_loss= 0.6442, rmse = 18.192\n",
      "IT № 500/739, tr_loss= 0.6346, eval_loss= 0.6449, rmse = 18.262\n",
      "IT № 520/739, tr_loss= 0.6346, eval_loss= 0.646, rmse = 18.357\n",
      "IT № 540/739, tr_loss= 0.6343, eval_loss= 0.6478, rmse = 18.517\n",
      "IT № 560/739, tr_loss= 0.6344, eval_loss= 0.646, rmse = 18.359\n",
      "IT № 580/739, tr_loss= 0.6338, eval_loss= 0.645, rmse = 18.25\n",
      "IT № 600/739, tr_loss= 0.634, eval_loss= 0.6444, rmse = 18.193\n",
      "IT № 620/739, tr_loss= 0.634, eval_loss= 0.6435, rmse = 18.101\n",
      "IT № 640/739, tr_loss= 0.6341, eval_loss= 0.6437, rmse = 18.159\n",
      "IT № 660/739, tr_loss= 0.6341, eval_loss= 0.6442, rmse = 18.208\n",
      "IT № 680/739, tr_loss= 0.6338, eval_loss= 0.6449, rmse = 18.276\n",
      "IT № 700/739, tr_loss= 0.6337, eval_loss= 0.6457, rmse = 18.356\n",
      "IT № 720/739, tr_loss= 0.6336, eval_loss= 0.6443, rmse = 18.235\n",
      "Epoch № 3, tr_loss= 0.6333, eval_loss= 0.645, rmse = 18.28255748252349 \n",
      "time_per_epoch = 2430.8 sec, total ---> 5451.6 sec\n",
      "**************************************** EPOCH № 4 ****************************************\n",
      "IT № 20/739, tr_loss= 0.6411, eval_loss= 0.6474, rmse = 18.571\n",
      "IT № 40/739, tr_loss= 0.6385, eval_loss= 0.6458, rmse = 18.406\n",
      "IT № 60/739, tr_loss= 0.6329, eval_loss= 0.6443, rmse = 18.199\n",
      "IT № 80/739, tr_loss= 0.6336, eval_loss= 0.6439, rmse = 18.145\n",
      "IT № 100/739, tr_loss= 0.6321, eval_loss= 0.6463, rmse = 18.451\n",
      "IT № 120/739, tr_loss= 0.6335, eval_loss= 0.6456, rmse = 18.361\n",
      "IT № 140/739, tr_loss= 0.6323, eval_loss= 0.6435, rmse = 18.111\n",
      "IT № 160/739, tr_loss= 0.629, eval_loss= 0.646, rmse = 18.37\n",
      "IT № 180/739, tr_loss= 0.6275, eval_loss= 0.646, rmse = 18.378\n",
      "IT № 200/739, tr_loss= 0.6277, eval_loss= 0.6469, rmse = 18.461\n",
      "IT № 220/739, tr_loss= 0.6272, eval_loss= 0.648, rmse = 18.574\n",
      "IT № 240/739, tr_loss= 0.6273, eval_loss= 0.646, rmse = 18.353\n",
      "IT № 260/739, tr_loss= 0.6277, eval_loss= 0.6457, rmse = 18.37\n",
      "IT № 280/739, tr_loss= 0.6268, eval_loss= 0.6436, rmse = 18.152\n",
      "IT № 300/739, tr_loss= 0.6265, eval_loss= 0.6448, rmse = 18.255\n",
      "IT № 320/739, tr_loss= 0.6269, eval_loss= 0.6446, rmse = 18.208\n",
      "IT № 340/739, tr_loss= 0.6269, eval_loss= 0.6437, rmse = 18.119\n",
      "IT № 360/739, tr_loss= 0.6267, eval_loss= 0.6467, rmse = 18.457\n",
      "IT № 380/739, tr_loss= 0.6267, eval_loss= 0.6465, rmse = 18.441\n",
      "IT № 400/739, tr_loss= 0.6277, eval_loss= 0.6452, rmse = 18.3\n",
      "IT № 420/739, tr_loss= 0.628, eval_loss= 0.6433, rmse = 18.057\n",
      "IT № 440/739, tr_loss= 0.6279, eval_loss= 0.6451, rmse = 18.272\n",
      "IT № 460/739, tr_loss= 0.6285, eval_loss= 0.6453, rmse = 18.285\n",
      "IT № 480/739, tr_loss= 0.6276, eval_loss= 0.6467, rmse = 18.423\n",
      "IT № 500/739, tr_loss= 0.628, eval_loss= 0.6452, rmse = 18.236\n",
      "IT № 520/739, tr_loss= 0.6276, eval_loss= 0.6459, rmse = 18.342\n",
      "IT № 540/739, tr_loss= 0.6281, eval_loss= 0.6455, rmse = 18.309\n",
      "IT № 560/739, tr_loss= 0.6286, eval_loss= 0.6455, rmse = 18.366\n",
      "IT № 580/739, tr_loss= 0.6285, eval_loss= 0.6448, rmse = 18.276\n",
      "IT № 600/739, tr_loss= 0.6288, eval_loss= 0.6457, rmse = 18.38\n",
      "IT № 620/739, tr_loss= 0.6291, eval_loss= 0.6462, rmse = 18.462\n",
      "IT № 640/739, tr_loss= 0.6291, eval_loss= 0.6443, rmse = 18.22\n",
      "IT № 660/739, tr_loss= 0.6287, eval_loss= 0.6437, rmse = 18.106\n",
      "IT № 680/739, tr_loss= 0.6288, eval_loss= 0.6454, rmse = 18.34\n",
      "IT № 700/739, tr_loss= 0.6289, eval_loss= 0.6441, rmse = 18.194\n",
      "IT № 720/739, tr_loss= 0.629, eval_loss= 0.6448, rmse = 18.29\n",
      "Epoch № 4, tr_loss= 0.629, eval_loss= 0.6447, rmse = 18.26775426458618 \n",
      "time_per_epoch = 2414.4 sec, total ---> 7865.9 sec\n",
      "**************************************** EPOCH № 5 ****************************************\n",
      "IT № 20/739, tr_loss= 0.6251, eval_loss= 0.6448, rmse = 18.272\n",
      "IT № 40/739, tr_loss= 0.6334, eval_loss= 0.6448, rmse = 18.253\n",
      "IT № 60/739, tr_loss= 0.6337, eval_loss= 0.6456, rmse = 18.372\n",
      "IT № 80/739, tr_loss= 0.6311, eval_loss= 0.6454, rmse = 18.342\n",
      "IT № 100/739, tr_loss= 0.6298, eval_loss= 0.646, rmse = 18.423\n",
      "IT № 120/739, tr_loss= 0.6313, eval_loss= 0.6457, rmse = 18.389\n",
      "IT № 140/739, tr_loss= 0.6319, eval_loss= 0.6462, rmse = 18.435\n",
      "IT № 160/739, tr_loss= 0.6315, eval_loss= 0.6463, rmse = 18.478\n",
      "IT № 180/739, tr_loss= 0.6301, eval_loss= 0.6453, rmse = 18.347\n",
      "IT № 200/739, tr_loss= 0.631, eval_loss= 0.6439, rmse = 18.178\n",
      "IT № 220/739, tr_loss= 0.6306, eval_loss= 0.6474, rmse = 18.571\n",
      "IT № 240/739, tr_loss= 0.6298, eval_loss= 0.6466, rmse = 18.436\n",
      "IT № 260/739, tr_loss= 0.6305, eval_loss= 0.6446, rmse = 18.247\n",
      "IT № 280/739, tr_loss= 0.629, eval_loss= 0.6443, rmse = 18.206\n",
      "IT № 300/739, tr_loss= 0.6286, eval_loss= 0.6459, rmse = 18.392\n",
      "IT № 320/739, tr_loss= 0.6277, eval_loss= 0.6453, rmse = 18.295\n",
      "IT № 340/739, tr_loss= 0.6279, eval_loss= 0.6473, rmse = 18.518\n",
      "IT № 360/739, tr_loss= 0.6281, eval_loss= 0.6452, rmse = 18.278\n",
      "IT № 380/739, tr_loss= 0.6284, eval_loss= 0.6445, rmse = 18.193\n",
      "IT № 400/739, tr_loss= 0.6281, eval_loss= 0.6455, rmse = 18.278\n",
      "IT № 420/739, tr_loss= 0.6277, eval_loss= 0.6456, rmse = 18.372\n",
      "IT № 440/739, tr_loss= 0.6277, eval_loss= 0.6458, rmse = 18.351\n",
      "IT № 460/739, tr_loss= 0.628, eval_loss= 0.6461, rmse = 18.406\n",
      "IT № 480/739, tr_loss= 0.6277, eval_loss= 0.6456, rmse = 18.34\n",
      "IT № 500/739, tr_loss= 0.6277, eval_loss= 0.6446, rmse = 18.233\n",
      "IT № 520/739, tr_loss= 0.6272, eval_loss= 0.6455, rmse = 18.372\n",
      "IT № 540/739, tr_loss= 0.627, eval_loss= 0.6466, rmse = 18.483\n",
      "IT № 560/739, tr_loss= 0.6272, eval_loss= 0.6445, rmse = 18.213\n",
      "IT № 580/739, tr_loss= 0.6272, eval_loss= 0.6466, rmse = 18.439\n",
      "IT № 600/739, tr_loss= 0.6276, eval_loss= 0.6461, rmse = 18.413\n",
      "IT № 620/739, tr_loss= 0.6272, eval_loss= 0.6478, rmse = 18.611\n",
      "IT № 640/739, tr_loss= 0.6274, eval_loss= 0.6471, rmse = 18.517\n",
      "IT № 660/739, tr_loss= 0.6275, eval_loss= 0.6459, rmse = 18.386\n",
      "IT № 680/739, tr_loss= 0.6271, eval_loss= 0.6453, rmse = 18.32\n",
      "IT № 700/739, tr_loss= 0.627, eval_loss= 0.6448, rmse = 18.23\n",
      "IT № 720/739, tr_loss= 0.6267, eval_loss= 0.6464, rmse = 18.383\n",
      "Epoch № 5, tr_loss= 0.6266, eval_loss= 0.647, rmse = 18.443033002914834 \n",
      "time_per_epoch = 2416.5 sec, total ---> 10282.5 sec\n",
      "**************************************** EPOCH № 6 ****************************************\n",
      "IT № 20/739, tr_loss= 0.6276, eval_loss= 0.6471, rmse = 18.502\n",
      "IT № 40/739, tr_loss= 0.6285, eval_loss= 0.6477, rmse = 18.534\n",
      "IT № 60/739, tr_loss= 0.6299, eval_loss= 0.6447, rmse = 18.211\n",
      "IT № 80/739, tr_loss= 0.628, eval_loss= 0.6454, rmse = 18.294\n",
      "IT № 100/739, tr_loss= 0.6267, eval_loss= 0.6458, rmse = 18.374\n",
      "IT № 120/739, tr_loss= 0.6255, eval_loss= 0.646, rmse = 18.364\n",
      "IT № 140/739, tr_loss= 0.6248, eval_loss= 0.647, rmse = 18.492\n",
      "IT № 160/739, tr_loss= 0.6256, eval_loss= 0.6469, rmse = 18.496\n",
      "IT № 180/739, tr_loss= 0.6257, eval_loss= 0.646, rmse = 18.37\n",
      "IT № 200/739, tr_loss= 0.6254, eval_loss= 0.6471, rmse = 18.536\n",
      "IT № 220/739, tr_loss= 0.6248, eval_loss= 0.6472, rmse = 18.525\n",
      "IT № 240/739, tr_loss= 0.6247, eval_loss= 0.6464, rmse = 18.411\n",
      "IT № 260/739, tr_loss= 0.6249, eval_loss= 0.6454, rmse = 18.288\n",
      "IT № 280/739, tr_loss= 0.6249, eval_loss= 0.6479, rmse = 18.62\n",
      "IT № 300/739, tr_loss= 0.6249, eval_loss= 0.6472, rmse = 18.503\n",
      "IT № 320/739, tr_loss= 0.6245, eval_loss= 0.6473, rmse = 18.575\n",
      "IT № 340/739, tr_loss= 0.6236, eval_loss= 0.6463, rmse = 18.438\n",
      "IT № 360/739, tr_loss= 0.6247, eval_loss= 0.6452, rmse = 18.269\n",
      "IT № 380/739, tr_loss= 0.6249, eval_loss= 0.6475, rmse = 18.583\n",
      "IT № 400/739, tr_loss= 0.6248, eval_loss= 0.6458, rmse = 18.37\n",
      "IT № 420/739, tr_loss= 0.6245, eval_loss= 0.6475, rmse = 18.57\n",
      "IT № 440/739, tr_loss= 0.6252, eval_loss= 0.6451, rmse = 18.275\n",
      "IT № 460/739, tr_loss= 0.6256, eval_loss= 0.6472, rmse = 18.511\n",
      "IT № 480/739, tr_loss= 0.6252, eval_loss= 0.6464, rmse = 18.441\n",
      "IT № 500/739, tr_loss= 0.6252, eval_loss= 0.6458, rmse = 18.373\n",
      "IT № 520/739, tr_loss= 0.6252, eval_loss= 0.6458, rmse = 18.335\n",
      "IT № 540/739, tr_loss= 0.6249, eval_loss= 0.6466, rmse = 18.47\n",
      "IT № 560/739, tr_loss= 0.6249, eval_loss= 0.6475, rmse = 18.524\n",
      "IT № 580/739, tr_loss= 0.6249, eval_loss= 0.6455, rmse = 18.297\n",
      "IT № 600/739, tr_loss= 0.6246, eval_loss= 0.6458, rmse = 18.344\n",
      "IT № 620/739, tr_loss= 0.6245, eval_loss= 0.6464, rmse = 18.433\n",
      "IT № 640/739, tr_loss= 0.6244, eval_loss= 0.6469, rmse = 18.528\n",
      "IT № 660/739, tr_loss= 0.6247, eval_loss= 0.6466, rmse = 18.456\n",
      "IT № 680/739, tr_loss= 0.6245, eval_loss= 0.645, rmse = 18.238\n",
      "IT № 700/739, tr_loss= 0.6244, eval_loss= 0.6454, rmse = 18.3\n",
      "IT № 720/739, tr_loss= 0.6245, eval_loss= 0.6457, rmse = 18.337\n",
      "Epoch № 6, tr_loss= 0.6246, eval_loss= 0.6469, rmse = 18.47822098237976 \n",
      "time_per_epoch = 2424.7 sec, total ---> 12707.1 sec\n",
      "**************************************** EPOCH № 7 ****************************************\n",
      "IT № 20/739, tr_loss= 0.6222, eval_loss= 0.6442, rmse = 18.181\n",
      "IT № 40/739, tr_loss= 0.6259, eval_loss= 0.6465, rmse = 18.466\n",
      "IT № 60/739, tr_loss= 0.6244, eval_loss= 0.6466, rmse = 18.46\n",
      "IT № 80/739, tr_loss= 0.6254, eval_loss= 0.6473, rmse = 18.525\n",
      "IT № 100/739, tr_loss= 0.6234, eval_loss= 0.6449, rmse = 18.234\n",
      "IT № 120/739, tr_loss= 0.6245, eval_loss= 0.6445, rmse = 18.218\n",
      "IT № 140/739, tr_loss= 0.6249, eval_loss= 0.6458, rmse = 18.371\n",
      "IT № 160/739, tr_loss= 0.6251, eval_loss= 0.6462, rmse = 18.419\n",
      "IT № 180/739, tr_loss= 0.6232, eval_loss= 0.6472, rmse = 18.531\n",
      "IT № 200/739, tr_loss= 0.624, eval_loss= 0.6456, rmse = 18.293\n",
      "IT № 220/739, tr_loss= 0.6237, eval_loss= 0.6447, rmse = 18.25\n",
      "IT № 240/739, tr_loss= 0.6239, eval_loss= 0.6451, rmse = 18.273\n",
      "IT № 260/739, tr_loss= 0.6233, eval_loss= 0.6458, rmse = 18.374\n",
      "IT № 280/739, tr_loss= 0.6238, eval_loss= 0.6461, rmse = 18.398\n",
      "IT № 300/739, tr_loss= 0.6242, eval_loss= 0.6474, rmse = 18.492\n",
      "IT № 320/739, tr_loss= 0.6246, eval_loss= 0.6463, rmse = 18.42\n",
      "IT № 340/739, tr_loss= 0.6243, eval_loss= 0.6453, rmse = 18.36\n",
      "IT № 360/739, tr_loss= 0.6248, eval_loss= 0.6473, rmse = 18.542\n",
      "IT № 380/739, tr_loss= 0.6244, eval_loss= 0.647, rmse = 18.524\n",
      "IT № 400/739, tr_loss= 0.6243, eval_loss= 0.6448, rmse = 18.195\n",
      "IT № 420/739, tr_loss= 0.6241, eval_loss= 0.6458, rmse = 18.379\n",
      "IT № 440/739, tr_loss= 0.624, eval_loss= 0.6479, rmse = 18.617\n",
      "IT № 460/739, tr_loss= 0.6243, eval_loss= 0.6475, rmse = 18.547\n",
      "IT № 480/739, tr_loss= 0.625, eval_loss= 0.6461, rmse = 18.401\n",
      "IT № 500/739, tr_loss= 0.625, eval_loss= 0.6461, rmse = 18.384\n",
      "IT № 520/739, tr_loss= 0.6244, eval_loss= 0.6445, rmse = 18.197\n",
      "IT № 540/739, tr_loss= 0.6241, eval_loss= 0.6474, rmse = 18.535\n",
      "IT № 560/739, tr_loss= 0.6241, eval_loss= 0.6459, rmse = 18.353\n",
      "IT № 580/739, tr_loss= 0.6241, eval_loss= 0.6466, rmse = 18.471\n",
      "IT № 600/739, tr_loss= 0.6241, eval_loss= 0.6455, rmse = 18.339\n",
      "IT № 620/739, tr_loss= 0.6239, eval_loss= 0.6479, rmse = 18.629\n",
      "IT № 640/739, tr_loss= 0.624, eval_loss= 0.6463, rmse = 18.405\n",
      "IT № 660/739, tr_loss= 0.624, eval_loss= 0.6461, rmse = 18.36\n",
      "IT № 680/739, tr_loss= 0.6242, eval_loss= 0.6467, rmse = 18.47\n",
      "IT № 700/739, tr_loss= 0.6243, eval_loss= 0.6469, rmse = 18.473\n",
      "IT № 720/739, tr_loss= 0.6241, eval_loss= 0.6463, rmse = 18.356\n",
      "Epoch № 7, tr_loss= 0.6239, eval_loss= 0.6491, rmse = 18.712356262021515 \n",
      "time_per_epoch = 2420.2 sec, total ---> 15127.3 sec\n",
      "**************************************** EPOCH № 8 ****************************************\n",
      "IT № 20/739, tr_loss= 0.6202, eval_loss= 0.6458, rmse = 18.295\n",
      "IT № 40/739, tr_loss= 0.6206, eval_loss= 0.6476, rmse = 18.555\n",
      "IT № 60/739, tr_loss= 0.6212, eval_loss= 0.6466, rmse = 18.418\n",
      "IT № 80/739, tr_loss= 0.6223, eval_loss= 0.6463, rmse = 18.408\n",
      "IT № 100/739, tr_loss= 0.62, eval_loss= 0.6482, rmse = 18.615\n",
      "IT № 120/739, tr_loss= 0.6194, eval_loss= 0.647, rmse = 18.462\n",
      "IT № 140/739, tr_loss= 0.6218, eval_loss= 0.6469, rmse = 18.465\n",
      "IT № 160/739, tr_loss= 0.6233, eval_loss= 0.6464, rmse = 18.396\n",
      "IT № 180/739, tr_loss= 0.623, eval_loss= 0.6472, rmse = 18.512\n",
      "IT № 200/739, tr_loss= 0.6223, eval_loss= 0.6475, rmse = 18.548\n",
      "IT № 220/739, tr_loss= 0.6227, eval_loss= 0.6474, rmse = 18.551\n",
      "IT № 240/739, tr_loss= 0.6222, eval_loss= 0.648, rmse = 18.629\n",
      "IT № 260/739, tr_loss= 0.6222, eval_loss= 0.6475, rmse = 18.577\n",
      "IT № 280/739, tr_loss= 0.6219, eval_loss= 0.6472, rmse = 18.499\n",
      "IT № 300/739, tr_loss= 0.6215, eval_loss= 0.6474, rmse = 18.53\n",
      "IT № 320/739, tr_loss= 0.6213, eval_loss= 0.6474, rmse = 18.583\n",
      "IT № 340/739, tr_loss= 0.6216, eval_loss= 0.6458, rmse = 18.349\n",
      "IT № 360/739, tr_loss= 0.6213, eval_loss= 0.6473, rmse = 18.518\n",
      "IT № 380/739, tr_loss= 0.6222, eval_loss= 0.6474, rmse = 18.548\n",
      "IT № 400/739, tr_loss= 0.6226, eval_loss= 0.6476, rmse = 18.545\n",
      "IT № 420/739, tr_loss= 0.6225, eval_loss= 0.6457, rmse = 18.337\n",
      "IT № 440/739, tr_loss= 0.623, eval_loss= 0.6473, rmse = 18.525\n",
      "IT № 460/739, tr_loss= 0.623, eval_loss= 0.6454, rmse = 18.323\n",
      "IT № 480/739, tr_loss= 0.6225, eval_loss= 0.6454, rmse = 18.313\n",
      "IT № 500/739, tr_loss= 0.6224, eval_loss= 0.6459, rmse = 18.382\n",
      "IT № 520/739, tr_loss= 0.6225, eval_loss= 0.6474, rmse = 18.536\n",
      "IT № 540/739, tr_loss= 0.6227, eval_loss= 0.6461, rmse = 18.366\n",
      "IT № 560/739, tr_loss= 0.6225, eval_loss= 0.6468, rmse = 18.473\n",
      "IT № 580/739, tr_loss= 0.6224, eval_loss= 0.6456, rmse = 18.363\n",
      "IT № 600/739, tr_loss= 0.6226, eval_loss= 0.6469, rmse = 18.508\n",
      "IT № 620/739, tr_loss= 0.6229, eval_loss= 0.6455, rmse = 18.326\n",
      "IT № 640/739, tr_loss= 0.623, eval_loss= 0.6474, rmse = 18.535\n",
      "IT № 660/739, tr_loss= 0.6231, eval_loss= 0.6468, rmse = 18.519\n",
      "IT № 680/739, tr_loss= 0.6232, eval_loss= 0.6447, rmse = 18.194\n",
      "IT № 700/739, tr_loss= 0.6231, eval_loss= 0.6461, rmse = 18.383\n",
      "IT № 720/739, tr_loss= 0.6236, eval_loss= 0.6455, rmse = 18.293\n",
      "Epoch № 8, tr_loss= 0.6235, eval_loss= 0.6458, rmse = 18.383238969247014 \n",
      "time_per_epoch = 2421.4 sec, total ---> 17548.8 sec\n",
      "****************************************************************************************************\n",
      "Training is finished! Best score: 18.23534683139946 Time taken, sec: 17548.78478693962\n"
     ]
    }
   ],
   "source": [
    "train_start = time.time()\n",
    "rmse_history = []\n",
    "best_metric = 1000\n",
    "step = 300\n",
    "for epoch in tqdm_notebook(range(EPOCHES)):\n",
    "    print('*'*40, f'EPOCH № {epoch+1}', '*'*40)\n",
    "    rmse, best_metric = train_step(epoch,\n",
    "                      train_start,\n",
    "                      net2,\n",
    "                      opt,\n",
    "                      criterion,\n",
    "                      train_loader,\n",
    "                      step,\n",
    "                      best_metric\n",
    "                     )\n",
    "\n",
    "        \n",
    "    if best_metric < 20:\n",
    "        step = 60\n",
    "        if best_metric < 18.6:\n",
    "            step = 20\n",
    "            if (best_metric < 18.1) or (epoch > 4):\n",
    "                step = 20\n",
    "            \n",
    "        \n",
    "        \n",
    "    rmse_history.append(rmse)\n",
    "    scheduler.step()\n",
    "print('*'*100)\n",
    "print(f'Training is finished! Best score: {min(rmse_history)} Time taken, sec:',\n",
    "      time.time()-train_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "deacaa7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-20T13:59:44.201990Z",
     "iopub.status.busy": "2021-11-20T13:59:44.199632Z",
     "iopub.status.idle": "2021-11-20T13:59:44.202795Z",
     "shell.execute_reply": "2021-11-20T13:59:44.203355Z"
    },
    "papermill": {
     "duration": 0.148868,
     "end_time": "2021-11-20T13:59:44.203521",
     "exception": false,
     "start_time": "2021-11-20T13:59:44.054653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pred(model, loss_func, dataset_loader):\n",
    "\n",
    "    num_batches = len(dataset_loader)\n",
    "    test_loss = 0\n",
    "    full_pred = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for X, features, y in dataset_loader:\n",
    "            pred = model(X.to(device), features.to(device))\n",
    "            if y is not None:\n",
    "                test_loss += criterion(pred, y.to(device)).item()\n",
    "            full_pred = np.append(full_pred, pred.cpu().numpy())\n",
    "        if y is not None:\n",
    "            test_loss = round(test_loss / num_batches, 4)\n",
    "            rmse = round(np.sqrt(test_loss), 2)\n",
    "            return full_pred, rmse\n",
    "            \n",
    "\n",
    "    return full_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17601.525995,
   "end_time": "2021-11-20T13:59:50.169990",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-20T09:06:28.643995",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "3aa8583451be45229f5820db185352a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cae9699261c44a4392bda3e767b7beac",
       "max": 8,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3cdf12ca2aa24fd085e9abfc7e701355",
       "value": 8
      }
     },
     "3cdf12ca2aa24fd085e9abfc7e701355": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6dcb24ff4af1440795a72069bcff546e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6e1f739b3d734b7cbb29812b6195b3a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "744448fb3bf2451cbe5b27c559d249ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "85d9f5856c9d4cd7bbee0d20d28f7344": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6e1f739b3d734b7cbb29812b6195b3a3",
       "placeholder": "​",
       "style": "IPY_MODEL_bb269d1fab86406e8959a0fd03cc087f",
       "value": "100%"
      }
     },
     "bb269d1fab86406e8959a0fd03cc087f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cad8c5788b0140e7b5448dcb4be35429": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_744448fb3bf2451cbe5b27c559d249ad",
       "placeholder": "​",
       "style": "IPY_MODEL_6dcb24ff4af1440795a72069bcff546e",
       "value": " 8/8 [4:52:28&lt;00:00, 2373.43s/it]"
      }
     },
     "cae9699261c44a4392bda3e767b7beac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "deb39ab4b1504e94b9eccaac5120aa2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa73d9a9e5b44ae7b37cb9bd6b56cc1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_85d9f5856c9d4cd7bbee0d20d28f7344",
        "IPY_MODEL_3aa8583451be45229f5820db185352a3",
        "IPY_MODEL_cad8c5788b0140e7b5448dcb4be35429"
       ],
       "layout": "IPY_MODEL_deb39ab4b1504e94b9eccaac5120aa2c"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
